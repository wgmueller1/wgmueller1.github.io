---
layout: post
title: Deep Learning for Time Series, pt. 1
description: ""
modified: 2016-07-09
tags: [machine,learning,deep,lstm,recurrent,convolutional,time,series]
comments: true
published: true
image:
  feature: 
  credit: 
  creditlink: 
---

<section id="table-of-contents" class="toc">
  <header>
    <h3>Contents</h3>
  </header>
<div id="drawer" markdown="1">
*  Auto generated table of contents
{:toc}
</div>
</section><!-- /#table-of-contents -->

Time series data occur almost everywhere.  Much of the recent hype (mostly deserved) around deep learning architectures has been around the state-of-the-art performance produced in the fields of computer vision, natural language processing, and bioinformatics.  Much of "deep learning" is a rebranding of neural networks.  During my second year of graduate school, I became interested in applying machine learning to time series data which I planned to use as my dissertation topic.  I ended up studying reinforcement learning in social graphs, but I'll save that for another time.  

###Convolutional Neural Networks

>Convolutional Neural Networks (CNN) are biologically-inspired variants of MLPs. From Hubel and Wiesel’s early work on the cat’s visual cortex, we know the visual cortex contains a complex arrangement of cells. These cells are sensitive to small sub-regions of the visual field, called a receptive field. The sub-regions are tiled to cover the entire visual field. These cells act as local filters over the input space and are well-suited to exploit the strong spatially local correlation present in natural images.<sup>[1](#myfootnote1)</sup>

<p>
    <center><img src="/images/Typical_cnn.png"><br>
    <em>Typical CNN architecture</em></center>
</p>
<br>
CNNs may be applied to multivariate time series.  It can be useful to think of a time series as a one-dimensional image.  You don't need to use an image of the time series as input to the CNN!  I've seen several papers which used this approach which seems weird, you just need to use a 1-dimensional convolutional layer instead of the typical 2-D layer.
<br>
<br>

<p>
    <center><img src="/images/1d_convolution_ex"><br>
    <em>Example of 1-D Convolution</em></center>
</p>

###Data

I'm going to use the UCI Machine Learning <a href="https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones">Human Activity Recognition dataset</a> for this example.  The dataset consists of sensor data recorded from 30 subjects performing activities of daily living, specifically, WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.  The data was collected from 30 individuals who wore a Samsung Galaxy S II on their waist.  The sampling rate was 50Hz and sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window).  If you don't care about any of this and just want an input into your blackbox, we have 128 observations of a 9-dimensional time series with 6 unique classes.


<p>
    <center><img src="/images/raw.png"><br>
    <em>Raw sensor data from mobile phone</em></center>
</p>


###Example

{% highlight python %}
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flat
from keras.layers.convolutional import Convolution1D, MaxPooling1D

#set parameters
batch_size = 1
nb_filter = 100
filter_length= 128 #number of time observations per sample
hidden_dims = 150
nb_epoch = 10
nb_sensors = 9 #input dimension
classes = 6

model = Sequential()

model.add(Convolution1D(nb_filter=nb_filter,filter_length=filter_length,\
border_mode='valid',activation='relu',subsample_length=25,\
input_dim=nb_sensors,input_lenght=128))

model.add(Flatten())

model.add(Dense(hidden_dims))
model.add(Dense(classes))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy',optimizer='rmsprop')
model.fit(xtrain,ytrain,batch_size=batch_size,nb_epoch=nb_epoch,show_accuracy=True)




{% endhighlight %}


We can look at the distribution and correlations of the extracted features using the following code.

{% highlight python %}
import seaborn as sns
import pandas as pd
from keras import backend as K

def get_activations(model,layer_idx,X-batch):
	get_activations = K.function([model.layers[0].input, K.learning_phase()],model.layers[layer_idx].output,])
	activations = get_activations([X_batch,0])
	return activations

feats=np.squeeze(activations[0])
features=pd.DataFrame(feats[:,0:10])
features['labels']=np.argmax(ytrain,axis=1)
sns.pairplot(features,hue='labels')


{% endhighlight %}

<img src="/images/features.png">

The confusion matrix 


<a name="myfootnote1">1</a>: http://deeplearning.net/tutorial/lenet.html