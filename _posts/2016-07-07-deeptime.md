---
layout: post
title: Deep Learning for Time Series, pt. 1
description: ""
modified: 2016-07-09
tags: [machine,learning,deep,lstm,recurrent,convolutional,time,series]
comments: true
published: true
image:
  feature: 
  credit: 
  creditlink: 
---

<section id="table-of-contents" class="toc">
  <header>
    <h3>Contents</h3>
  </header>
<div id="drawer" markdown="1">
*  Auto generated table of contents
{:toc}
</div>
</section><!-- /#table-of-contents -->

Time series data occur almost everywhere.  Much of the recent hype (mostly deserved) around deep learning architectures has been around the state-of-the-art performance produced in the fields of computer vision, natural language processing, and bioinformatics.  Much of "deep learning" is a rebranding of neural networks.  During my second year of graduate school, I became interested in applying machine learning to time series data which I planned to use as my dissertation topic.  I ended up studying reinforcement learning in social graphs, but I'll save that for another time.  In this tutorial, I'll discuss applying convolutional neural networks to time series data.

### Convolutional Neural Networks

>Convolutional Neural Networks (CNN) are biologically-inspired variants of MLPs. From Hubel and Wiesel’s early work on the cat’s visual cortex, we know the visual cortex contains a complex arrangement of cells. These cells are sensitive to small sub-regions of the visual field, called a receptive field. The sub-regions are tiled to cover the entire visual field. These cells act as local filters over the input space and are well-suited to exploit the strong spatially local correlation present in natural images.<sup>[1](#myfootnote1)</sup>

<p>
    <center><img src="/images/Typical_cnn.png"><br>
    <em>Typical CNN architecture</em></center>
</p>
<br>
CNNs may be applied to multivariate time series.  It can be useful to think of a time series as a one-dimensional image.  You don't need to use an image of the time series as input to the CNN!  I've seen several papers which used this approach which seems weird, you just need to use a 1-dimensional convolutional layer instead of the typical 2-D layer.  In the 1D domain, a convolution can be viewed as a filter, capable of removing outliers, filtering the data or acting as a feature detector, defined to respond maximally to specific temporal sequences within the filter length of the convolution. 
<br>
<br>
To better understand this, consider the definition of a 1-D convolution.



$$y_{k} = \sum_{n = 0}^{N - 1}h_{n}\,\cdot\,x_{k-n}$$

<p>There are two input signals, <em>x</em> and <em>h</em> and <em>N</em> is the length of <em>h</em>. The output vector is <em>y</em>, <em>h</em> is known as the kernel or convolution filter and <em>x</em> is the input data.  The subscripts denote the <em>n</em>th element of the vector. Here is an example of how the convolution is calculated when <em style="line-height: 1.5em;">h</em> has three elements:</p><br>
<p>$$<br />\begin{aligned}<br />y_{0} & = h_{0} \cdot x_{0} \\<br />y_{1} & = h_{1} \cdot x_{0} + h_{0} \cdot x_{1} \\<br />y_{2} & = h_{2} \cdot x_{0} + h_{1} \cdot x_{1} + h_{0} \cdot x_{2} \\<br />y_{3} & = h_{2} \cdot x_{1} + h_{1} \cdot x_{2} + h_{0} \cdot x_{3} \\<br />\vdots<br />\end{aligned}<br />$$</p>
<br>
The filter [$$h_2 h_1 h_0$$] is slid along the elements of <em>x</em> and at each step we multiply the elements and sum them: the result will be the corresponding element of the output <em>y</em> vector.  Here is a concrete example:
<br>
<p>$$<br />\begin{aligned}<br />x & = \left[<br />\begin{array}{c} 1 \, 2 \, 1 \, 3<br />\end{array}<br />\right]<br />\\<br />h & = \left[<br />\begin{array}{c}<br />2 \, 0 \, 1<br />\end{array}<br />\right]<br />\end{aligned}<br />\\<br />\begin{array}{c|cccccccc|r}<br />k & \it{0} & \it{0} & 1 & 2 & 1 & 3 & \it{0} & \it{0} & \it{y_{k}}\\<br />\hline<br />0 & 1 & 0 & 2 & & & & & & 2 \cdot 1 = 2\\<br />1 & & 1 & 0 & 2 & & & & & 2 \cdot 2 = 4\\<br />2 & & & 1 & 0 & 2 & & & & 2 \cdot 1 + 1 \cdot 1 = 3\\<br />3 & & & & 1 & 0 & 2 & & & 2 \cdot 3 + 1 \cdot 2 = 8\\<br />4 & & & & & 1 & 0 & 2 & & 1 \cdot 1 = 1\\<br />5 & & & & & & 1 & 0 & 2 & 1 \cdot 3 = 3\\<br />\end{array}<br />$$</p>
<br>
It is easy to see that a simple moving average is a special case of a convolution using the following kernel:<br>

<p>$$<br />h = \left[<br />\begin{array}{c} \dfrac{1}{N} \, \dfrac{1}{N} \, ... \, \dfrac{1}{N}\, \dfrac{1}{N}\end{array}<br />\right]<br />$$</p>
<br>
<br>

Hopefully, this gives some intuition as to what a one-dimensional convolution does. A 1-dimensional convolution applied to multiple input signals creates a linear combination of the filtered inputs at each time step.     


### Data

I'm going to use the UCI Machine Learning <a href="https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones">Human Activity Recognition dataset</a> for this example.  The dataset consists of sensor data recorded from 30 subjects performing activities of daily living, specifically, WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING.  The data was collected from 30 individuals who wore a Samsung Galaxy S II on their waist.  The sampling rate was 50Hz and sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window).  If you don't care about any of this and just want an input into your blackbox, we have 128 observations of a 9-dimensional time series with 6 unique classes.


<p>
    <center><img src="/images/raw.png"><br>
    <em>De-noised sensor data from mobile phone</em></center>
</p>


### Example

I'm a big fan of the neural networks library <a href="http://keras.io" target="_blank">Keras</a>.  Keras can run on top of the deep learning libraries Theano and Tensorflow and makes prototyping neural networks very easy.  Here I'll use Keras to build a convolutional neural network to predict the activities from the sensor data provided by Human Activity Recognition dataset.

{% highlight python %}
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flat
from keras.layers.convolutional import Convolution1D, MaxPooling1D

#set parameters 
batch_size = 50
nb_filter = 64 #number of features to learn
filter_length = 10 #number of time steps
hidden_dims = 250
nb_epoch = 50
n_sensors = 9
classes = 6
pool_length = 64
subsample_length = 2


model = Sequential()

model.add(Convolution1D(nb_filter=64,
                        filter_length=10,
                        subsample_length=subsample_length,
                        border_mode='same',input_shape=(128,9)))
# we use standard max pooling (halving the output of the previous layer):
model.add(MaxPooling1D(pool_length=pool_length))
# We flatten the output of the conv layer,
# so that we can add a vanilla dense layer:
model.add(Flatten())

model.add(Dense(hidden_dims))
model.add(Dense(classes))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy',optimizer='rmsprop')
model.fit(xtrain,ytrain,batch_size=batch_size,nb_epoch=nb_epoch,show_accuracy=True)




{% endhighlight %}

<!--
After training the model, we can look at the output of each layer using the following code to get a better sense of what is happening inside the neural network.  In this case, the convolutional layer maps the raw input into 64 seperate time series each of length 64 and the max pooling layer condenses these into a single time series of length 64.  


{% highlight python %}
import seaborn as sns
import pandas as pd
from keras import backend as K

def get_activations(model,layer_idx,X-batch):
	get_activations = K.function([model.layers[0].input, K.learning_phase()],model.layers[layer_idx].output,])
	activations = get_activations([X_batch,0])
	return activations

#the following plots the first 32 activation outputs 
# (the middle plot in the figure below)
fig, ax = plt.subplots(32,1)

#t = np.arange(0, 1, 0.01)
activations = get_activations(model,0,xtrain) # same result as above
plt.plot(activations[0][1,:,:].T)

for i, a in enumerate(ax):
    a.plot(activations[0][-1,i,:].T)
    a.set_xlim([0,128])
    a.set_ylim([np.min(activations[0][-1,i,:]), np.max(activations[0][-1,i,:])])
    a.axis('off')

plt.show()

{% endhighlight %}

<img src="/images/cnn_filters.png">
-->
After training the model, we can look at some of the learned filters to get a sense of what types of features the CNN extracts.

<div class="container" style="inline-block">
    <figure>
    <img src="/images/filters2.png" width="300">
    <img src="/images/filters.png" width="300">
    </figure>

   

  </div>

Some common feature extractors can be represented as convolution filters.  For example, the derivative of an input signal can be approximated by convolving the derivative of a Gaussian Filter.  




### Results

Test set summary:

    class   precision    recall  f1-score   support
    0         0.98      0.92      0.95       496
    1         0.95      0.94      0.94       471
    2         0.89      1.00      0.94       420
    3         0.86      0.92      0.89       491
    4         0.96      0.87      0.91       532
    5         1.00      1.00      1.00       537

    total      0.94      0.94      0.94      2947


Training set summary:

    class   precision   recall  f1-score   support

    0         1.00      1.00      1.00      1226
    1         1.00      1.00      1.00      1073
    2         1.00      1.00      1.00       986
    3         0.91      1.00      0.95      1286
    4         1.00      0.91      0.95      1374
    5         1.00      1.00      1.00      1407

    total     0.98      0.98      0.98      7352



A 1-layer convolutional + max pooling neural network achieves 94% accuracy with somewhat arbitrary hyperparameters (I choose the parameters to help simplify the visualizations of each of the activations.) This is a good start, but we can improve performance by adding additional layers.  In part 2, I will discuss adding recurrent layers in order to better capture the temporal dynamics.

<br>
<br>
<a name="myfootnote1">1</a>: http://deeplearning.net/tutorial/lenet.html
